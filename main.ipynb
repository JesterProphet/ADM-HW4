{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d533db7",
   "metadata": {},
   "source": [
    "# Homework 4 - Recommendation systems and clustering everywhere\n",
    "\n",
    "#### Group 9 <br>\n",
    "\n",
    "<div style=\"float: left;\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <th>Student</th>\n",
    "            <th>GitHub</th>\n",
    "            <th>Matricola</th>\n",
    "            <th>E-Mail</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Andr√© Leibrant</td>\n",
    "            <td>JesterProphet</td>\n",
    "            <td>2085698</td>\n",
    "            <td>leibrant.2085698@studenti.uniroma1.it</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92df7e45",
   "metadata": {},
   "source": [
    "#### Import Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b56fbef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80cd71db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47951fae",
   "metadata": {},
   "source": [
    "## 1. Recommendation sytem\n",
    "Implementing a recommendation system is critical for businesses and digital platforms that want to thrive in today's competitive environment. These systems use data-driven personalization to tailor content, products, and services to individual user preferences. The latter improves user engagement, satisfaction, retention, and revenue through increased sales and cross-selling opportunities. In this section, you will attempt to implement a recommendation system by identifying similar users' preferences and recommending movies they watch to the study user.\n",
    "\n",
    "To be more specific, you will implement your version of the [LSH algorithm](https://www.learndatasci.com/tutorials/building-recommendation-engine-locality-sensitive-hashing-lsh-python/), which will take as input the user's preferred genre of movies, find the most similar users to this user, and recommend the most watched movies by those who are more similar to the user.\n",
    "\n",
    "**Data:** The data you will be working with can be found [here](https://www.kaggle.com/datasets/vodclickstream/netflix-audience-behaviour-uk-movies).\n",
    "\n",
    "Looking at the data, you can see that there is data available for each user for the movies the user <u>clicked on</u>. Gather the **title** and **genre** of the **maximum top 10 movies** that each user clicked on regarding the **number of clicks**.\n",
    "\n",
    "---\n",
    "\n",
    "First we are reading the data into a Pandas DataFrame. Then we do a little bit of preprocessing:\n",
    "1. Droping the `row ID` column because we don't need it\n",
    "2. Converting the `datatime` column to a date\n",
    "3. Converting the `release_date` column to a date\n",
    "4. Extracting the `genres` column to a new column `genre_list` that includes a list with all genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "659c07cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data into a Pandas DataFrame\n",
    "dataset = pd.read_csv(\"vodclickstream_uk_movies_03.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17364dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Row ID column\n",
    "dataset.drop(dataset.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Convert datetime column to a date\n",
    "dataset.datetime = pd.to_datetime(dataset.datetime)\n",
    "\n",
    "# Convert release_date column to a date\n",
    "dataset.release_date = pd.to_datetime(dataset.release_date, errors=\"coerce\")\n",
    "\n",
    "# Extract genres column to a new column genre_list that includes a list with all genres\n",
    "dataset[\"genre_list\"] = dataset.genres.apply(lambda row: [word.strip() for word in row.split(\",\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b69a1e5",
   "metadata": {},
   "source": [
    "In the next step we are defining a function `top_10_movies` that takes a `user_id` and extracts the top 10 most clicked movies by the user. For this we can easily group by the columns `user_id`, `movie_id`, `title`, and `genres` and create a new aggregation column called `clicks`. At the end we sort the column `clicks` in ascending order and return only the top 10 entries including only the desired columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8ec5826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_10_movies(user_id: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function that takes a user id and returns the top 10 most clicked movies by the user.\n",
    "\n",
    "    Args:\n",
    "        user_id (str): User ID.\n",
    "\n",
    "    Returns:\n",
    "        top_10_movies (pd.DataFrame): Pandas DataFrame that includes the top 10 most clicked movies by the user.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter all movies for given user\n",
    "    movies = dataset[dataset[\"user_id\"] == user_id]\n",
    "\n",
    "    # Extract the top 10 movies regarding the number of clicks for the given user\n",
    "    movies = movies.groupby([\"user_id\", \"movie_id\", \"title\", \"genres\"]).size().reset_index(name=\"clicks\")\n",
    "    top_10_movies = movies.sort_values(by=\"clicks\", ascending=False).head(10)[[\"title\", \"genres\", \"clicks\"]]\n",
    "\n",
    "    # Reset the index of the dataframe\n",
    "    top_10_movies.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    return top_10_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951a88d8",
   "metadata": {},
   "source": [
    "This is an example output for the user `b15926c011`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d41c4107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>clicks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wild Child</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zapped</td>\n",
       "      <td>Comedy, Family, Fantasy</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barely Lethal</td>\n",
       "      <td>Action, Comedy</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Horror</td>\n",
       "      <td>Crime, Drama, Horror, Mystery, Thriller</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Innocence</td>\n",
       "      <td>Fantasy, Horror, Mystery, Romance, Thriller</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>You Get Me</td>\n",
       "      <td>Crime, Drama, Romance, Thriller</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Minor Details</td>\n",
       "      <td>Adventure, Family, Mystery</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The 5th Wave</td>\n",
       "      <td>Action, Adventure, Sci-Fi, Thriller</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IBOY</td>\n",
       "      <td>Action, Crime, Sci-Fi, Thriller</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Molly Moon and the Incredible Book of Hypnotism</td>\n",
       "      <td>Adventure, Family, Fantasy</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title  \\\n",
       "0                                       Wild Child   \n",
       "1                                           Zapped   \n",
       "2                                    Barely Lethal   \n",
       "3                                          #Horror   \n",
       "4                                        Innocence   \n",
       "5                                       You Get Me   \n",
       "6                                    Minor Details   \n",
       "7                                     The 5th Wave   \n",
       "8                                             IBOY   \n",
       "9  Molly Moon and the Incredible Book of Hypnotism   \n",
       "\n",
       "                                        genres  clicks  \n",
       "0                       Comedy, Drama, Romance      23  \n",
       "1                      Comedy, Family, Fantasy      19  \n",
       "2                               Action, Comedy      18  \n",
       "3      Crime, Drama, Horror, Mystery, Thriller      16  \n",
       "4  Fantasy, Horror, Mystery, Romance, Thriller      13  \n",
       "5              Crime, Drama, Romance, Thriller      12  \n",
       "6                   Adventure, Family, Mystery      12  \n",
       "7          Action, Adventure, Sci-Fi, Thriller      10  \n",
       "8              Action, Crime, Sci-Fi, Thriller      10  \n",
       "9                   Adventure, Family, Fantasy      10  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given user id\n",
    "user_id = \"b15926c011\"\n",
    "\n",
    "# Retrive top 10 movies of given user regarding the clicks\n",
    "top_10_movies(user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bf5402",
   "metadata": {},
   "source": [
    "### 1.2 Minhash Signatures\n",
    "Using the movie genre and user_ids, try to implement your min-hash signatures so that users with similar interests in a genre appear in the same bucket.\n",
    "\n",
    "**Important note:** You must write your minhash function from scratch. You are not permitted to use any already implemented hash functions. Read the class materials and, if necessary, conduct an internet search. The description of hash functions in the [book](http://infolab.stanford.edu/~ullman/mmds/ch3n.pdf) may be helpful as a reference.\n",
    "\n",
    "---\n",
    "\n",
    "First we create a list `unique_genres` that includes the unique values of all genres across our data. We use the `capture` hint so that we suppress the output of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e759591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Retrieve a list with all unique genres\n",
    "unique_genres = set()\n",
    "dataset[\"genre_list\"].apply(lambda row: [unique_genres.add(value) for value in row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c290f98",
   "metadata": {},
   "source": [
    "Based on this list we can create a new column `one_hot_genre_list` that includes only 0s and 1s which is at the end a binary representation of the genres of a movie where a 1 on the i-th position represents the genre in the i-th position in the `unique_genres` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b32013da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the genre list (which we treat as our shingles) of every movie to a one-hot list\n",
    "dataset[\"one_hot_genre_list\"] = dataset[\"genre_list\"].apply(\n",
    "    lambda genre_list: [1 if genre in genre_list else 0 for genre in unique_genres]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2e575c",
   "metadata": {},
   "source": [
    "In the next step we defined our minhash function in the following way: We decided on choosing a similarity signature based on 12 different hash functions, all defined in the function `hash_function` which takes the binary representation of the genres of a movie in `one_hot_genre_list` and returns the similarity signature. The modulo of all hash functions is based on the highest value the term before the modulo can take from which we then took the closest or seconds closest prime number (larger than the highest value the term before can take) to make our hash functions as precise as possible and avoid coellisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeb3d03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_function(element: List) -> List:\n",
    "    \"\"\"\n",
    "    Function that takes a list of integer numbers and returns all results based on 12 different hash functions.\n",
    "\n",
    "    Args:\n",
    "        element (List): List of integer numbers.\n",
    "\n",
    "    Returns:\n",
    "        hashes_result (List): Hash function results.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create an empty list of size 12\n",
    "    hashes_result = [None]*12\n",
    "    \n",
    "    # Calculate every value of the values of the given list based on 12 different hash functions\n",
    "    hashes_result[0] = (element + 1) % 29\n",
    "    hashes_result[1] = (3*element + 1) % 83\n",
    "    hashes_result[2] = (2*element + 4) % 59\n",
    "    hashes_result[3] = (3*element - 1) % 83\n",
    "    hashes_result[4] = (element << 1) % 59\n",
    "    hashes_result[5] = (element >> 1) % 19\n",
    "    hashes_result[6] = (element << 2) % 109\n",
    "    hashes_result[7] = (element >> 2) % 11\n",
    "    hashes_result[8] = (element << 3) % 211\n",
    "    hashes_result[9] = (element >> 3) % 7\n",
    "    hashes_result[10] = (element << 4) % 421\n",
    "    hashes_result[11] = (element >> 4) % 5\n",
    "    \n",
    "    return hashes_result\n",
    "\n",
    "\n",
    "def minhash(genre_list: List) -> List:\n",
    "    \"\"\"\n",
    "    Function that takes a list of genres based on a binary representation and returns its minhash similarity\n",
    "    signature.\n",
    "\n",
    "    Args:\n",
    "        genre_list (List): List of genres based on a binary representation.\n",
    "\n",
    "    Returns:\n",
    "        similarity_signature (List): Minhash Similarity Signature.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create list of size 12 and inf as the default value\n",
    "    similarity_signature = [float(\"inf\")]*12\n",
    "\n",
    "    # Iterate through every element of the genre list\n",
    "    for row_index, genre in enumerate(genre_list):\n",
    "        \n",
    "        # Calculate the hash values of the current genre and skip otherwise\n",
    "        if genre == 1:\n",
    "            \n",
    "            # Retrieve hash values of current genre based on the row index\n",
    "            hashes_result = hash_function(row_index)\n",
    "            \n",
    "            # Only update the similarity signature if a new hash value is smaller then the current one\n",
    "            for i in range(0, 12):\n",
    "                similarity_signature[i] = min(similarity_signature[i], hashes_result[i])\n",
    "\n",
    "    return similarity_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e443e7",
   "metadata": {},
   "source": [
    "Using `hash_function` we create a new column `minhash` transforming the binary representation in `one_hot_genre_list` to the similariy signature of every movie.\n",
    "\n",
    "**Note:** We are decreasing from `n = len(unique_genres)` elements to 12!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45223797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the minhash similarity signature for every movie\n",
    "dataset[\"minhash\"] = dataset[\"one_hot_genre_list\"].apply(lambda genre_list: minhash(genre_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dfb384",
   "metadata": {},
   "source": [
    "Finally we define our LSH function `lsh` which transforms every similarity signature based on the given number of buckets `b` and number of rows `r` to the final band of hashes based on the same hash function on every bucket. We decided on using the inbuild `hash` function for our LSH hashing on every bucket. The retrieved value we then divide by a very large prime number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15202fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsh(similarity_signature: List, num_buckets: int, num_rows: int) -> List:\n",
    "    \"\"\"\n",
    "    Function that transforms a taken similarity signature based on the given number of buckets and number of rows\n",
    "    to the final band of hashes using the same hash function for every bucket.\n",
    "\n",
    "    Args:\n",
    "        similarity_signature (List): Minhash Similarity Signature.\n",
    "        num_buckets(int): Number of buckets the Similarity Signature is devided in.\n",
    "        num_rows(int): Number of rows every bucket has.\n",
    "\n",
    "    Returns:\n",
    "        band_hashes (List): Final band of hashes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set seed for reproducibility\n",
    "    random.seed(42)\n",
    "\n",
    "    # Create empty list\n",
    "    band_hashes = []\n",
    "\n",
    "    # Iterate through every bucket\n",
    "    for bucket_start in range(0, len(similarity_signature), num_rows):\n",
    "        \n",
    "        # Extract current bucket\n",
    "        bucket = similarity_signature[bucket_start:bucket_start+num_rows]\n",
    "        \n",
    "        # Calculate band hash for current bucket\n",
    "        band_hash = hash(tuple(bucket)) % 997\n",
    "        \n",
    "        # Append hash value to final band\n",
    "        band_hashes.append(band_hash)\n",
    "\n",
    "    return band_hashes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee5fb99",
   "metadata": {},
   "source": [
    "Using `lsh` we create a new column `lsh_bands` transforming the Minhash Similarity Signature of every movie to the final LSH band.\n",
    "\n",
    "**Note:** We are decreasing from `n = 12` elements to 4!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a131d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given number of buckets and number of rows\n",
    "num_buckets = 4\n",
    "num_rows = 3\n",
    "\n",
    "# Create LSH band for every movie\n",
    "dataset[\"lsh_bands\"] = dataset[\"minhash\"].apply(lambda similarity_signature: lsh(similarity_signature,\n",
    "                                                                                 num_buckets,\n",
    "                                                                                 num_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bcf5dd",
   "metadata": {},
   "source": [
    "In the following output you can see the dataset with all newly created columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "724bb68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>duration</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>release_date</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>genre_list</th>\n",
       "      <th>one_hot_genre_list</th>\n",
       "      <th>minhash</th>\n",
       "      <th>lsh_bands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 01:15:09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Angus, Thongs and Perfect Snogging</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>2008-07-25</td>\n",
       "      <td>26bd5987e8</td>\n",
       "      <td>1dea19f6fe</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[10, 28, 22, 26, 18, 4, 36, 2, 72, 1, 144, 0]</td>\n",
       "      <td>[633, 444, 12, 337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 13:56:02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Curse of Sleeping Beauty</td>\n",
       "      <td>Fantasy, Horror, Mystery, Thriller</td>\n",
       "      <td>2016-06-02</td>\n",
       "      <td>f26ed2675e</td>\n",
       "      <td>544dcbc510</td>\n",
       "      <td>[Fantasy, Horror, Mystery, Thriller]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]</td>\n",
       "      <td>[4, 10, 10, 8, 6, 1, 12, 0, 24, 0, 48, 0]</td>\n",
       "      <td>[509, 720, 23, 637]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 15:17:47</td>\n",
       "      <td>10530.0</td>\n",
       "      <td>London Has Fallen</td>\n",
       "      <td>Action, Thriller</td>\n",
       "      <td>2016-03-04</td>\n",
       "      <td>f77e500e7a</td>\n",
       "      <td>7cbcc791bf</td>\n",
       "      <td>[Action, Thriller]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]</td>\n",
       "      <td>[23, 67, 48, 65, 44, 11, 88, 5, 176, 2, 352, 1]</td>\n",
       "      <td>[314, 318, 336, 587]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 16:04:13</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Vendetta</td>\n",
       "      <td>Action, Drama</td>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>c74aec7673</td>\n",
       "      <td>ebf43c36b6</td>\n",
       "      <td>[Action, Drama]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>[10, 28, 22, 26, 18, 4, 36, 2, 72, 1, 144, 0]</td>\n",
       "      <td>[633, 444, 12, 337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 19:16:37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The SpongeBob SquarePants Movie</td>\n",
       "      <td>Animation, Action, Adventure, Comedy, Family, Fantasy</td>\n",
       "      <td>2004-11-19</td>\n",
       "      <td>a80d6fc2aa</td>\n",
       "      <td>a57c992287</td>\n",
       "      <td>[Animation, Action, Adventure, Comedy, Family, Fantasy]</td>\n",
       "      <td>[0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>[2, 4, 6, 2, 2, 0, 4, 0, 8, 0, 16, 0]</td>\n",
       "      <td>[456, 205, 387, 463]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671731</th>\n",
       "      <td>2019-06-30 21:37:08</td>\n",
       "      <td>851.0</td>\n",
       "      <td>Oprah Presents When They See Us Now</td>\n",
       "      <td>Talk-Show</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>43cd23f30f</td>\n",
       "      <td>57501964fd</td>\n",
       "      <td>[Talk-Show]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[21, 61, 44, 59, 40, 10, 80, 5, 160, 2, 320, 1]</td>\n",
       "      <td>[528, 439, 642, 244]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671732</th>\n",
       "      <td>2019-06-30 21:49:34</td>\n",
       "      <td>91157.0</td>\n",
       "      <td>HALO Legends</td>\n",
       "      <td>Animation, Action, Adventure, Family, Sci-Fi</td>\n",
       "      <td>2010-02-16</td>\n",
       "      <td>febf42d55f</td>\n",
       "      <td>d4fcb079ba</td>\n",
       "      <td>[Animation, Action, Adventure, Family, Sci-Fi]</td>\n",
       "      <td>[0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0]</td>\n",
       "      <td>[2, 4, 6, 2, 2, 0, 4, 0, 8, 0, 16, 0]</td>\n",
       "      <td>[456, 205, 387, 463]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671733</th>\n",
       "      <td>2019-06-30 22:00:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pacific Rim</td>\n",
       "      <td>Action, Adventure, Sci-Fi</td>\n",
       "      <td>2013-07-12</td>\n",
       "      <td>7b15e5ada1</td>\n",
       "      <td>4a14a2cd5a</td>\n",
       "      <td>[Action, Adventure, Sci-Fi]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]</td>\n",
       "      <td>[2, 4, 6, 2, 2, 0, 4, 0, 8, 0, 16, 0]</td>\n",
       "      <td>[456, 205, 387, 463]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671734</th>\n",
       "      <td>2019-06-30 22:04:23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ReMastered: The Two Killings of Sam Cooke</td>\n",
       "      <td>Documentary, Music</td>\n",
       "      <td>2019-02-08</td>\n",
       "      <td>52d49c515a</td>\n",
       "      <td>0b8163ea4b</td>\n",
       "      <td>[Documentary, Music]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[8, 22, 18, 20, 14, 3, 28, 1, 56, 0, 112, 0]</td>\n",
       "      <td>[912, 665, 787, 981]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671735</th>\n",
       "      <td>2019-06-30 22:35:24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Chopsticks</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>0be62aac8b</td>\n",
       "      <td>5e5755d816</td>\n",
       "      <td>[Comedy, Drama]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[10, 28, 22, 26, 18, 4, 36, 2, 72, 1, 144, 0]</td>\n",
       "      <td>[633, 444, 12, 337]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671736 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime  duration  \\\n",
       "0      2017-01-01 01:15:09       0.0   \n",
       "1      2017-01-01 13:56:02       0.0   \n",
       "2      2017-01-01 15:17:47   10530.0   \n",
       "3      2017-01-01 16:04:13      49.0   \n",
       "4      2017-01-01 19:16:37       0.0   \n",
       "...                    ...       ...   \n",
       "671731 2019-06-30 21:37:08     851.0   \n",
       "671732 2019-06-30 21:49:34   91157.0   \n",
       "671733 2019-06-30 22:00:44       0.0   \n",
       "671734 2019-06-30 22:04:23       0.0   \n",
       "671735 2019-06-30 22:35:24       0.0   \n",
       "\n",
       "                                            title  \\\n",
       "0              Angus, Thongs and Perfect Snogging   \n",
       "1                    The Curse of Sleeping Beauty   \n",
       "2                               London Has Fallen   \n",
       "3                                        Vendetta   \n",
       "4                 The SpongeBob SquarePants Movie   \n",
       "...                                           ...   \n",
       "671731        Oprah Presents When They See Us Now   \n",
       "671732                               HALO Legends   \n",
       "671733                                Pacific Rim   \n",
       "671734  ReMastered: The Two Killings of Sam Cooke   \n",
       "671735                                 Chopsticks   \n",
       "\n",
       "                                                       genres release_date  \\\n",
       "0                                      Comedy, Drama, Romance   2008-07-25   \n",
       "1                          Fantasy, Horror, Mystery, Thriller   2016-06-02   \n",
       "2                                            Action, Thriller   2016-03-04   \n",
       "3                                               Action, Drama   2015-06-12   \n",
       "4       Animation, Action, Adventure, Comedy, Family, Fantasy   2004-11-19   \n",
       "...                                                       ...          ...   \n",
       "671731                                              Talk-Show   2019-06-12   \n",
       "671732           Animation, Action, Adventure, Family, Sci-Fi   2010-02-16   \n",
       "671733                              Action, Adventure, Sci-Fi   2013-07-12   \n",
       "671734                                     Documentary, Music   2019-02-08   \n",
       "671735                                          Comedy, Drama   2019-05-31   \n",
       "\n",
       "          movie_id     user_id  \\\n",
       "0       26bd5987e8  1dea19f6fe   \n",
       "1       f26ed2675e  544dcbc510   \n",
       "2       f77e500e7a  7cbcc791bf   \n",
       "3       c74aec7673  ebf43c36b6   \n",
       "4       a80d6fc2aa  a57c992287   \n",
       "...            ...         ...   \n",
       "671731  43cd23f30f  57501964fd   \n",
       "671732  febf42d55f  d4fcb079ba   \n",
       "671733  7b15e5ada1  4a14a2cd5a   \n",
       "671734  52d49c515a  0b8163ea4b   \n",
       "671735  0be62aac8b  5e5755d816   \n",
       "\n",
       "                                                     genre_list  \\\n",
       "0                                      [Comedy, Drama, Romance]   \n",
       "1                          [Fantasy, Horror, Mystery, Thriller]   \n",
       "2                                            [Action, Thriller]   \n",
       "3                                               [Action, Drama]   \n",
       "4       [Animation, Action, Adventure, Comedy, Family, Fantasy]   \n",
       "...                                                         ...   \n",
       "671731                                              [Talk-Show]   \n",
       "671732           [Animation, Action, Adventure, Family, Sci-Fi]   \n",
       "671733                              [Action, Adventure, Sci-Fi]   \n",
       "671734                                     [Documentary, Music]   \n",
       "671735                                          [Comedy, Drama]   \n",
       "\n",
       "                                                                       one_hot_genre_list  \\\n",
       "0       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]   \n",
       "2       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]   \n",
       "3       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]   \n",
       "4       [0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]   \n",
       "...                                                                                   ...   \n",
       "671731  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]   \n",
       "671732  [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0]   \n",
       "671733  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]   \n",
       "671734  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "671735  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                                minhash             lsh_bands  \n",
       "0         [10, 28, 22, 26, 18, 4, 36, 2, 72, 1, 144, 0]   [633, 444, 12, 337]  \n",
       "1             [4, 10, 10, 8, 6, 1, 12, 0, 24, 0, 48, 0]   [509, 720, 23, 637]  \n",
       "2       [23, 67, 48, 65, 44, 11, 88, 5, 176, 2, 352, 1]  [314, 318, 336, 587]  \n",
       "3         [10, 28, 22, 26, 18, 4, 36, 2, 72, 1, 144, 0]   [633, 444, 12, 337]  \n",
       "4                 [2, 4, 6, 2, 2, 0, 4, 0, 8, 0, 16, 0]  [456, 205, 387, 463]  \n",
       "...                                                 ...                   ...  \n",
       "671731  [21, 61, 44, 59, 40, 10, 80, 5, 160, 2, 320, 1]  [528, 439, 642, 244]  \n",
       "671732            [2, 4, 6, 2, 2, 0, 4, 0, 8, 0, 16, 0]  [456, 205, 387, 463]  \n",
       "671733            [2, 4, 6, 2, 2, 0, 4, 0, 8, 0, 16, 0]  [456, 205, 387, 463]  \n",
       "671734     [8, 22, 18, 20, 14, 3, 28, 1, 56, 0, 112, 0]  [912, 665, 787, 981]  \n",
       "671735    [10, 28, 22, 26, 18, 4, 36, 2, 72, 1, 144, 0]   [633, 444, 12, 337]  \n",
       "\n",
       "[671736 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20c4640",
   "metadata": {},
   "source": [
    "### 1.3 Locality-Sensitive Hashing (LSH)\n",
    "Now that your buckets are ready, it's time to ask a few queries. We will provide you with some user_ids and ask you to recommend at **most five movies** to the user to watch based on the movies clicked by similar users.\n",
    "\n",
    "To recommend at most five movies given a user_id, use the following procedure:\n",
    "1. Identify the <u>two most similar</u> users to this user.\n",
    "2. If these two users have any movies **in common**, recommend those movies based on the total number of clicks by these users.\n",
    "3. If there are **no more common** movies, try to propose the most clicked movies by the **most similar user first**, followed by the other user.\n",
    "\n",
    "**Note:** At the end of the process, we expect to see at most five movies recommended to the user.\n",
    "\n",
    "**Example:** assume you've identified user **A** and **B** as the most similar users to a single user, and we have the following records on these users:\n",
    "\n",
    "- User A with 80% similarity\n",
    "- User B with 50% similarity\n",
    "\n",
    "| user | movie title | #clicks |\n",
    "|----------|----------|----------|\n",
    "| A | Wild Child | 20 |\n",
    "| A | Innocence | 10 |\n",
    "| A | Coin Heist | 2 |\n",
    "| B | Innocence | 30 |\n",
    "| B | Coin Heist | 15 |\n",
    "| B | Before I Fall | 30 |\n",
    "| B | Beyond Skyline | 8 |\n",
    "| B | The Amazing Spider-Man | 5 |\n",
    "\n",
    "**Recommended movies** in order:\n",
    "- Innocence\n",
    "- Coin Heist\n",
    "- Wild Child\n",
    "- Before I Fall\n",
    "- Beyond Skyline\n",
    "\n",
    "---\n",
    "\n",
    "We are going to use the results in our final defined column `lsh_bands` to retrieve the two most similar users to a given user. We are defining the similarity inside the function `get_two_most_similar_users` in the following way: First we extract the unique `lsh_bands` of the given user. Then we retrieve all movies that have **exaclty** the same `lsh_band`. At last we group by the `user_id` and define two new aggregated values: The total `movie_count` of each user and based on the intersection in `lsh_bands` the `similarity` score which is the division of `lsh_bands_count` and the size of `user_lsh_bands`. We are using the `movie_count` as a tie breaker if the `similarity` score is the same. At the end we only return the first two entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d76c0847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_two_most_similar_users(user_id: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function that takes a user and returns the two most similar users based on the movie genres.\n",
    "\n",
    "    Args:\n",
    "        user_id (str): User ID.\n",
    "\n",
    "    Returns:\n",
    "        similar_users (pd.DataFrame): Pandas DataFrame with the two most similar users.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the unique lsh bands of the given user\n",
    "    user_lsh_bands = dataset[dataset[\"user_id\"] == user_id].drop_duplicates(subset=[\"lsh_bands\"])\n",
    "    user_lsh_bands = user_lsh_bands[\"lsh_bands\"].tolist()\n",
    "\n",
    "    # Create empty list\n",
    "    similar_movies = []\n",
    "    \n",
    "    # Iterate through every unique lsh band\n",
    "    for user_lsh_band in user_lsh_bands:\n",
    "        \n",
    "        # Only save the movies which have exactly the same lsh band\n",
    "        similar_movies.append(dataset[dataset[\"lsh_bands\"].apply(lambda lsh_band: lsh_band == user_lsh_band)])\n",
    "\n",
    "    # Transform result into a Pandas DataFrame\n",
    "    similar_movies = pd.concat(similar_movies)\n",
    "    \n",
    "    # Group by the user_id and lsh_bands and retrieve movie_count\n",
    "    similar_movies[\"lsh_bands\"] = similar_movies[\"lsh_bands\"].apply(tuple)\n",
    "    similar_users = similar_movies.groupby([\"user_id\", \"lsh_bands\"]).size().reset_index(name=\"movie_count\")\n",
    "    \n",
    "    # Group by the user_id and retrieve lsh_bands_count and movie_count for every user\n",
    "    similar_users = similar_users.groupby(\"user_id\").agg({\"lsh_bands\": \"count\", \"movie_count\": \"sum\"})\n",
    "    similar_users = similar_users.rename(columns={\"lsh_bands\": \"lsh_bands_count\",\n",
    "                                                  \"movie_count\": \"movie_count\"})\n",
    "    \n",
    "    # Calculate the similarity score for every user\n",
    "    similar_users[\"similarity\"] = (similar_users[\"lsh_bands_count\"] / len(user_lsh_bands)).round(2)\n",
    "    \n",
    "    # Sort by the highest similarity score and use movie_count as tie breaker\n",
    "    similar_users = similar_users.sort_values(by=[\"similarity\", \"movie_count\"], ascending=[False, False])\n",
    "    \n",
    "    # Remove the given user from the results and return only the first two users\n",
    "    similar_users = similar_users[similar_users.index != user_id].head(5)\n",
    "    \n",
    "    return similar_users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be4abde",
   "metadata": {},
   "source": [
    "In the following output you can see the two most similar users given the user `b15926c011`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7102b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsh_bands_count</th>\n",
       "      <th>movie_count</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>779343a3ea</th>\n",
       "      <td>13</td>\n",
       "      <td>484</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89fbb087f3</th>\n",
       "      <td>13</td>\n",
       "      <td>278</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322f2bd4d4</th>\n",
       "      <td>13</td>\n",
       "      <td>172</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9eaa2fc081</th>\n",
       "      <td>13</td>\n",
       "      <td>142</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e259fd87b7</th>\n",
       "      <td>12</td>\n",
       "      <td>162</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lsh_bands_count  movie_count  similarity\n",
       "user_id                                             \n",
       "779343a3ea               13          484        0.81\n",
       "89fbb087f3               13          278        0.81\n",
       "322f2bd4d4               13          172        0.81\n",
       "9eaa2fc081               13          142        0.81\n",
       "e259fd87b7               12          162        0.75"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given user id\n",
    "user_id = \"b15926c011\"\n",
    "\n",
    "# Retrieve the two most similar users given the user\n",
    "two_most_similar_users = get_two_most_similar_users(user_id)\n",
    "two_most_similar_users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a486d53",
   "metadata": {},
   "source": [
    "In the last step we are going to retrieve all movies from the two most similar users. We are adding the similarity score from the previous result because we are going to recommend first the movies which both users clicked on and then the movies from the most similar user using the clicks as a tie breaker. In the final result we are returning the top 5 movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf53f3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ed2f7aad6a</th>\n",
       "      <td>Natural Selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb1e870bea</th>\n",
       "      <td>6 Years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>080f74d403</th>\n",
       "      <td>Knock, Knock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b9ef0f30ff</th>\n",
       "      <td>Rip Tide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4884acf862</th>\n",
       "      <td>Candy Jar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        title\n",
       "movie_id                     \n",
       "ed2f7aad6a  Natural Selection\n",
       "fb1e870bea            6 Years\n",
       "080f74d403       Knock, Knock\n",
       "b9ef0f30ff           Rip Tide\n",
       "4884acf862          Candy Jar"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrive all movies from the two most similar users\n",
    "movies = dataset[dataset[\"user_id\"].isin(two_most_similar_users.index.tolist())]\n",
    "\n",
    "# Merge the movies with the previous table to add the similary score\n",
    "movies = pd.merge(two_most_similar_users, movies, on=\"user_id\")\n",
    "\n",
    "# Group by user_id, movie_id, and similarity and calcualate new aggregated value clicks\n",
    "movies = movies.groupby([\"user_id\", \"movie_id\", \"similarity\"]).size().reset_index(name=\"clicks\")\n",
    "movies = movies.groupby(\"movie_id\").agg({\"user_id\": \"count\", \"clicks\": \"sum\", \"similarity\": \"sum\"})\n",
    "movies = movies.rename(columns={\"user_id\": \"common\"})\n",
    "\n",
    "# Replace the similariy score with the similarity score of the most similar user if the score is larger than that\n",
    "threshold_similarity = two_most_similar_users.loc[two_most_similar_users.index[0], \"similarity\"]\n",
    "movies.loc[movies[\"similarity\"] > threshold_similarity,\"similarity\"] = threshold_similarity\n",
    "\n",
    "# Order by the common column first to recommend the movies which both users clicked on and than the movies from\n",
    "# the user with the highest similarity and clicks as the tie breaker and return only the first 5 movies\n",
    "movies = movies.sort_values(by=[\"common\", \"similarity\", \"clicks\"], ascending=[False, False, False]).head(5)\n",
    "\n",
    "# Retrieve the title of every movie and set movie_id as the index\n",
    "top_5_similar_movies = dataset[dataset[\"movie_id\"].isin(movies.index.tolist())]\n",
    "top_5_similar_movies = top_5_similar_movies.drop_duplicates(subset=[\"movie_id\"]).loc[:, [\"movie_id\", \"title\"]]\n",
    "top_5_similar_movies = top_5_similar_movies.reset_index(drop=True,inplace=False).set_index(\"movie_id\")\n",
    "top_5_similar_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7a3b51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.11",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
